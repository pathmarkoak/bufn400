{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Note \n",
    "\n",
    "# Numpy Arrays and Linear Algebra\n",
    "\n",
    "## By Albert S. \"Pete\" Kyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]\n",
      "NumPy version 1.23.5\n",
      "Timestamp: 2023-0825-1124\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "import timeit\n",
    "\n",
    "print('Python version ' + sys.version)\n",
    "print('NumPy version ' + np.__version__)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "print(\"Timestamp:\", timestamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Linear Algebra in Finance\n",
    "\n",
    "Financial analysis makes extensive use of linear algebra.\n",
    "\n",
    "These notes will review basic concepts of linear algebra, illustrating the concepts using Python's Numpy package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\require{\\newcommand}$\n",
    "$\\newcommand{\\E}{\\mathrm{E}}$\n",
    "$\\newcommand{\\e}{\\mathrm{e}}$\n",
    "$\\newcommand{\\drm}{\\mathrm{\\, d}}$\n",
    "$\\newcommand{\\var}{\\mathrm{var}}$\n",
    "$\\newcommand{\\stdev}{\\mathrm{stdev}}$\n",
    "$\\newcommand{\\sm}{ {\\scriptstyle{*}} }$ \n",
    "$\\renewcommand{\\mm}{{\\scriptsize @}}$\n",
    "$\\renewcommand{\\t}{^{\\mathsf{T}}}$\n",
    "$\\renewcommand{\\comma}{\\, , \\,}$\n",
    "$\\renewcommand{\\vec}[1]{\\mathbf{#1}}$\n",
    "\n",
    "\n",
    "### Math Notation\n",
    "\n",
    "I will try to follow a practice of using math notation and conventions that follow Python notation and conventions as closely as possible.\n",
    "\n",
    "Various subfields of math and science use different, conflicting, and ambiguous notation for the standard operations of inner product, matrix product, and scalar product. For example, a dot \"$\\cdot$\" sometimes means inner product and sometimes means scalar product. Similarly, some computer applications use an asterisk \"*\" to denote element-by-element multiplication (one example of which is a scalar product), while other computer applications use an asterisk to denote matrix multiplication.  Sometimes no explicit operator means matrix multiplication; other times it means scalar multiplication.\n",
    "\n",
    "To avoid such ambiguities when writing math, I will try to use Python-looking conventions:\n",
    "\n",
    "* An asterisk \"*\" denots scalar products or element-by-element products. If $r$ is a scalar and $\\vec{A}$ is a matrix, then $r \\sm \\vec{A}$ denotes the scalar product of $r$ and $\\vec{A}$.  The corresponding Python code would be `r * A`.\n",
    "\n",
    "* The \"at symbol\" \"@\" denotes inner products, matrix-vector products, and matrix-matrix products. If $\\vec{A}$ is a matrix and $\\vec{x}$ is a vector, then $\\vec{A} \\mm \\vec{x}$ denotes the matrix-vector product. The corresponding Python code would be `A @ x`.\n",
    "\n",
    "Various subfields of math and science also use different and conflicting notation for referring to the rows, columns, and elements of matrices. For example, the notation $\\vec{a}_n$ might mean the the $n$th element of a vector, the $n$th row of a matrix, or the $n$ array in a sequence of arrays.\n",
    "\n",
    "To avoid some ambiguities, I will use Python indexing conventions. \n",
    "\n",
    "* The notation $\\vec{a}[n]$ means the $n$th element of an array, such as the $n$th element of a vector. The corresponding Python code would be `a[n]`.\n",
    "\n",
    "* The notation $\\vec{a}[n,:]$ means the $n$th row of an matrix (two-dimensional array). The notation $\\vec{a}[n,m]$ denotes element $n,m$ of a matrix. The corresponding Python code would be `a[n, :]` and `a[n, m]`. \n",
    "\n",
    "I will use subscripts to denote names for different objects.\n",
    "\n",
    "* The math notation $a_i = 5$ might correspond to Python code `ai = 5`. \n",
    "\n",
    "Math and science often index $N$ elements of a sequence starting with 1, as $n = 1,2,\\ldots,N$. Sometimes indexing starts with 0, as $n=0,1,2,\\ldots, N-1$ \n",
    "\n",
    "* I will follow Python conventions and index $N$ elements as $0,1,2,\\ldots, N-1$.\n",
    "\n",
    "Various subfields of math and science also use different and conflicting notation for distinguishing among scalars, vectors, and matrices. For example, sometimes Greek letters denote scalars, lower-case Roman letter denote vectors, and upper-case Roman letters denote matrices.  While I will sometimes use this convention, I will not follow it rigorously.  \n",
    "\n",
    "* I will try to use bold-faced characters for vectors and matrices, non-bold-faced characters for scalars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars, Vectors, Matrices, and Arrays\n",
    "\n",
    "Linear algebra deals with mathematical operations involving vectors, matrices, and scalars.  A **scalar** is a number (like 1.234). Informally, a **vector** is a one-dimensional array of scalars.  A **matrix** is a two dimensional array of scalars. An array may be a vector, a matrix, or an array of more than two dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars in Python and Numpy\n",
    "\n",
    "Python itself has two typical scalar types, `int` and `float`. Numpy has several different scalar types, the most important of which are:\n",
    "\n",
    "* `np.int64`: The numpy type `np.int64`, the Python type `float`, and C type `double` are all essentially equivalent. Numbers are stored with 64 bits of data in the form $\\pm x \\sm 2^n$, where one bit stores the sign ($+$ or $-$), 52 bits store the **significand** $x$ with 53 bits of precision as a binary fraction between $1/2$ and $1$, and 11 bits store the exponent as say an integer between $-1023$ and $+1024$. With 53 binary digits, about 16 digits decimal precision are obtained.\n",
    "\n",
    "* `np.float32`: Stores floating point numbers in 32 bits with 1 bit for sign, 24 bits for significand, and 8 bits for the exponent. This gives slightly more than 7 decimal digits of precision.\n",
    "\n",
    "* `np.int64`: This is a signed integer, stored as 64 bits, representing numbers between approximately $\\pm 2^{63}$$. The unsigned version is `np.uint64`. This is not equivalent to the Python `int`, which can represent arbitrarily large integers.\n",
    "\n",
    "* `np.int32`: This is a signed integer stored in 32 bits, representing numbers between approximately $\\pm 2^{31}$. The unisgned version is `np.uint32`. There is no equivalent type in native Python.\n",
    "\n",
    "Given that computers are nowadays so powerful, you might wonder why `np.float32` would ever be used in preference to `np.float64`. There are several reasons:\n",
    "\n",
    "1. Even if calculations are fast, storage size may be an issue if billions of numbers need to be stored. Obviously, `np.float32` numbers take up half as much space as `np.float64`.\n",
    "\n",
    "2. Machine learning algorithms sometimes need to do a very large number of calculations which do not need to be very accurate. This favors `np.float32` over `np.float64`. Indeed, there is now increasing interest in `np.float16` types.\n",
    "\n",
    "3. Graphics cards are optimized to do calculations with `np.float32`. Multiplication is much more costly than addition. Multiplication of 64 bit integers \"theoretically\" takes 4 times as much computation time as multiplication of 32 bit integers. A similar ratio holds for `np.float32` versus `np.float64`. Graphics cards are often optimized to do calculations with types equivalent to `np.float32`; they frequently do 32-bit floating point calculations ten or more times faster than 64-bit calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about the numpy types using the functions `np.iinfo` and `np.finfo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.iinfo(np.int64).max = 9223372036854775807, 2**63 = 9223372036854775808, np.finfo(np.float64).min = -1.7976931348623157e+308\n",
      "np.float64(1234567890.12345678901234) = 1234567890.1234567 = 17 digits\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.iinfo(np.int64).max = }, {2**63 = }, {np.finfo(np.float64).min = }\")\n",
    "print(f\"{np.float64(1234567890.12345678901234) = } = 17 digits\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector\n",
    "\n",
    "A **vector** is a one dimensional array of numbers (scalars). In math notation, we write a vector $\\vec{x}$ with three elements as $\\vec{x} = [10,20,30]$, where the individual elements $\\vec{x}[0]=10$, $\\vec{x}[1]=20$, and $\\vec{x}[2]=30$ are scalars (integers or real numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy, a vector can be represented as an object of type `np.ndarray`, which is typically created with the function `np.array(...)`. An object of type `np.ndarray` is informally referred to as a \"numpy array\". All of the scalars have the same `dtype`, such as `np.float64` or `np.int64`.\n",
    "\n",
    "The `dtype` can be explicitly specified and queried. For example, here  is how to create the vector $\\vec{x} = [1.00, 3.00, 5.00]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=array([1., 3., 5.]), x.shape=(3,), type(x)=<class 'numpy.ndarray'>, x.dtype=dtype('float64')\n",
      "x[0]=1.0, type(x[0])=<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.00, 3.00, 5.00], dtype=np.float64)\n",
    "\n",
    "print(f\"{x=}, {x.shape=}, {type(x)=}, {x.dtype=}\")\n",
    "print(f\"{x[0]=}, {type(x[0])=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `np.array` is not a class. Instead, it is a numpy function which returns an object of class `np.ndarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(np.array)=<class 'builtin_function_or_method'>, type(np.ndarray)=<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{type(np.array)=}, {type(np.ndarray)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition and Scalar Multiplication\n",
    "\n",
    "Mathematically, vectors of the same shapes can be added together element by element and also multiplied by scalars.\n",
    "\n",
    "A **linear combination** is a vector obtained by a combination of addition and scalar multiplication, such as $\\vec{y} = \\alpha_0 \\sm \\vec{x}_0 + \\alpha_1 \\sm \\vec{x}_2$, where $\\alpha_0$ and $\\alpha_1$ are scalars and $x_0$ and $x_1$ are vectors.  The set of all possible linear combinations of $\\vec{x}$ and $\\vec{y}$ defines a **vector space** spanned by $\\vec{x}$ and $\\vec{y}$. Linear combinations of the vectors in a vector space are also in the vector space. Let $\\vec{0}_N$ denote a vector of $N$ zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a numpy example of a linear combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=array([310., 520., 740.])\n"
     ]
    }
   ],
   "source": [
    "a0 = 10.00\n",
    "a1 = 100.00\n",
    "x0 = np.array([1.00, 2.00, 4.00], dtype=np.float64)\n",
    "x1 = np.array([3.00, 5.00, 7.00], dtype=np.float64)\n",
    "y = a0 * x0 + a1 * x1\n",
    "\n",
    "print(f\"{y=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner product\n",
    " \n",
    "The **inner product** of two vectors $\\vec{x}$ and $\\vec{y}$ of length $N$ is defined as $\\vec{x} \\mm \\vec{y} = \\sum_{n=0}^{N-1} \\vec{x}[n] \\cdot \\vec{y}[n]$. For vectors with three elements, we have $\\vec{x} \\mm \\vec{y} := \\vec{x}[0] \\sm \\vec{y}[0] + \\vec{x}{1} \\sm \\vec{y}[1] + \\vec{x}[2] \\sm \\vec{y}[2]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several almost-equivalent ways of defining an inner product in numpy, using `np.dot(x0, x1)`, `x0.dot(x1)`, `x0 @ x1`, `np.matmul(x0, x1)`. I prefer the \"at\" operator version `x0 @ x1`, even though it may be noticably slower on small vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0=array([1., 2., 4.]), x1=array([3., 5., 7.])\n",
      "np.dot(x0, x1)=41.0\n",
      "x0.dot(x1)=41.0\n",
      "x0 @ x1=41.0\n",
      "np.matmul(x0,x1)=41.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x0=}, {x1=}\")\n",
    "print(f\"{np.dot(x0, x1)=}\")\n",
    "print(f\"{x0.dot(x1)=}\")\n",
    "print(f\"{x0 @ x1=}\")\n",
    "print(f\"{np.matmul(x0,x1)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric interpretation of inner product\n",
    "\n",
    "When the inner product of two vectors is zero, the vectors are **orthogonal** or **perpendicular**. In two dimensions, if the two vectors are represented as rays going from the origin to the point indexed by the elements of the array, the vectors will intersect at a right angle. This geometric interpretation generalizes to three dimensions. For four or more dimensions, geometric visualization is difficult but the geometric interpretation continues to apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean length, Norm\n",
    "\n",
    "A **norm** is a measure \"length\". Norms can be defined in different ways:\n",
    "\n",
    "1. The **Euclidean** length of a vector is defined as the square root of the inner product with itself: $\\lVert \\vec{x} \\rVert = \\sqrt{\\sum_{n=0}^{N-1} \\vec{x}[n]^2}$. In two or three dimensions, this measure of length is equivalent to the **Pythagorean Theorem**. It is often called the **$\\pmb{\\ell^2}$ norm**.\n",
    "\n",
    "2. The **sup norm** or **$\\pmb{\\ell^\\infty}$ norm** is defined as the maximum absolute value of all elements of a vector.\n",
    "\n",
    "3. The **$\\pmb{\\ell^1}$ norm**, defined as the sum of the absolute values of elements, measures \"Manhatten taxicab\" distance.\n",
    "\n",
    "The norm of the zero-vector is zero. For all norms, not just Euclidean distance, the norm satisfies the triangle inequality $\\lVert x + y \\rVert \\le \\lVert x \\rVert + \\lVert y \\rVert$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm: np.sqrt((v * v).sum()) =5.0, np.linalg.norm(v, ord=2)=5.0\n",
      "L1 norm: np.abs(v).sum()=7.0, np.linalg.norm(v, ord=1)=7.0\n",
      "sup norm np.abs(v).max()=4.0, np.linalg.norm(v, ord=np.inf)=4.0\n"
     ]
    }
   ],
   "source": [
    "v = np.array([3, 4], dtype=np.float64)\n",
    "print(f\"L2 norm: {np.sqrt((v * v).sum()) =}, {np.linalg.norm(v, ord=2)=}\")\n",
    "print(f\"L1 norm: {np.abs(v).sum()=}, {np.linalg.norm(v, ord=1)=}\")\n",
    "print(f\"sup norm {np.abs(v).max()=}, {np.linalg.norm(v, ord=np.inf)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Consider a vector of length 200, half of whose elements have a value of 0.00 and the other half a value of 1.00.\n",
    "\n",
    "1. Calculate the Euclidean norm, $\\ell^1$ norm, and $\\ell^\\infty$  norms of this vector in your head.\n",
    "\n",
    "2. Verify your calculation by constructing the vector and calclating its norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of norms\n",
    "\n",
    "Norms are important in machine learning. A typical machine learning algorithm constructs a vector which predicts another vector.  One measure of goodness of fit is the \"distance\" between the two vectors.  This distance is measured as the norm of the difference between two vectors. A typical machine learning algorithm tries to minimize this norm. Euclidean distance is minimized with **ordinary least squares**. Norms are also used to \"penalize\" parameters to reduce statistical noise. The $\\ell^1$ distance is minimized with **Lasso regression**.  If the norm of the difference between two vectors is zero, the two vectors are identical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "A **matrix** is a two-dimensional array of numbers (scalars). An $N \\times M$ matrix has $N$ rows and $M$ columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily create a matrix as a two-dimensional numpy array.  Here is a matrix of normally distributed random numbers with mean $100$ and standard deviation $10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85.76174964, 112.63728458,  91.29338262],\n",
       "       [ 97.40826765,  99.24656693,  92.59115348]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 2\n",
    "M = 3\n",
    "mu = 100.00\n",
    "sigma = 10.00\n",
    "rng = np.random.default_rng(seed=12345)\n",
    "x = rng.normal(loc=mu, scale=sigma, size=(N, M))\n",
    "display(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is typical to think of a matrix as $m$ column vectors, each of length $n$, stacked together sideways. \n",
    "\n",
    "Nevertheless, the display of the matrix $x$ above uses square brackets to suggest that the matrix consists of $n$ row vectors of length $m$, stacked together vertically. \n",
    "\n",
    "The data in matrices can be physically stored either by row (C style) or by column (Fortran style). Numpy stores the data as one contiguous (in memory) array of $n \\sm m$ numbers. The row and column structure of the matrix is simply an \"interpretation\" imposed on these numbers. The *shape* property gives the shape of the matrix, *size* gives the number of elements, and *ndim* gives the number of dimensions (which is 2 for a matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=(2, 3), x.size=6, x.ndim=2, x.dtype=dtype('float64')\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x.shape=}, {x.size=}, {x.ndim=}, {x.dtype=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix transpose\n",
    "\n",
    "The **transpose** of a matrix $\\vec{A}$, denoted $\\vec{A} \\t$, is the matrix obtained by switching rows and columns: $\\vec{A} \\t [n,m] := \\vec{A}[m,n]$.\n",
    "\n",
    "A **symmetric matrix** is a matrix which is equal to its transpose: $\\vec{A} = \\vec{A}^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the transpose of a matrix in numpy does not automatically change the underlying data. Only the interpretation of the data as rows and columns changes. To prevent sharing of data, use the `copy()` function.\n",
    "\n",
    "Notice the effect of data sharing in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = array([[999.99,   2.  ,   3.  ],\n",
      "       [  4.  ,   5.  ,   6.  ]])\n",
      "At = array([[999.99,   4.  ],\n",
      "       [  2.  ,   5.  ],\n",
      "       [  3.  ,   6.  ]])\n",
      "Atc = array([[1., 4.],\n",
      "       [2., 5.],\n",
      "       [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "A = np.array([1, 2, 3, 4, 5, 6], dtype=np.float64).reshape((2,3))\n",
    "At = A.T\n",
    "Atc = A.T.copy()\n",
    "A[0,0] = 999.99\n",
    "print(f\"{A = }\\n{At = }\\n{Atc = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Matrix-Vector product\n",
    "\n",
    "If $\\vec{A}$ is an $N \\times M$ matrix and $vec{x}$ is a vector with $M$ elements, then matrix-vector product $\\vec{y} := \\vec{A} \\mm \\vec{x}$ is a vector with $N$ elements and is defined by $\\vec{y}[n] := \\sum_{m=0}^{M-1} \\vec{A}[n, m] \\sm \\vec{x}[m]$.\n",
    "\n",
    "If we think of a matrix as column vectors stacked side-by-side, a matrix vector product defines a linear combination of the columns of the matrix, where the scalars multiplying the columns are the elements of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = array([[0., 1., 2.],\n",
      "       [3., 4., 5.]], dtype=float32)\n",
      "x = array([100.,  10.,   1.], dtype=float32)\n",
      "A @ x = array([ 12., 345.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "M = 3\n",
    "A = np.array(range(N * M), dtype=np.float32).reshape((N, M))\n",
    "x = np.array([100, 10, 1], dtype=np.float32)\n",
    "print(f\"{A = }\\n{x = }\\n{A @ x = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-matrix product\n",
    "\n",
    "If $\\vec{A}$ is an $N \\times M$ matrix and $\\vec{B}$ is an $M \\times K$ matrix, the matrix-matrix product $\\vec{C} := \\vec{A} \\mm \\vec{B}$ is the $N \\times K$ matrix defined by $\\vec{C}[n, k] := \\sum_{m=0}^{M-1} \\vec{A}[n, m] \\sm \\vec{B}[m, k]$. If we think of both $\\vec{A}$ and $\\vec{B}$ as column vectors stacked side by side, then $\\vec{A} \\mm \\vec{B}$ is consists of $K$ column vectors stack side by side, where each column vector is a linear combination of the columns of $\\vec{A}$ with scalar weights given by a column of $\\vec{B}$. In other words, the matrix-matrix product is $K$ matrix-vector products stacked side by side, one matrix-vector product for each column of $\\vec{B}$.\n",
    "\n",
    "The number of times element-by-element multiplication must be performed to calculate a matrix-matrix product is $N \\sm M \\sm K$. If the matrices are all large, matrix multiplication can be a time consuming operation. If the matrices are square ($N = M = K$), then matrix multiplication is an $O(N^3)$ operation because $N^3$ scalar multiplications must be performed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Independence, Basis\n",
    "\n",
    "The columns of an $N \\times M$ matrix $\\vec{A}$, interpreted as vectors, are **linearly independent** if the matrix-vector product $\\vec{A} \\mm \\vec{x}$ is a $N$-vector of zeros only when $\\vec{x}$ is an $M$-vector of zeros.\n",
    "\n",
    "If a set of vectors is linearly independent, then no vector in the set is an exact linear combination of the other vectors in the set.\n",
    "\n",
    "The **rank** of the matrix $\\vec{A}$ is the maximum number of columns in all linearly independent subsets of columns. The rank of a matrix $\\vec{A}$ is the same as the rank of its transpose $A\\t$. The rank $r$ satisfies $0 < r < M$. An $N \\times M$ matrix has **full rank** if its rank $r$ satisfied $r = \\min[N, M]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity matrix, matrix inverse, linear equations\n",
    "\n",
    "An $N \\times N$ matrix $\\vec{A}$ is a **diagonal matrix** if the only nonzero elements in the matrix are diagonal elements $\\vec{A}[n,n]$ for some $n$.\n",
    "\n",
    "The $N \\times N$ **identity** matrix, denoted $\\vec{I}_N$ or $\\vec{I}_{N N}$ is and $N \\times N$ matrix with ones on the diagonal and zeros off the diagonal.\n",
    "\n",
    "The **inverse** of $\\vec{A}$, denoted $\\vec{A}^{-1}$ is a matrix such that its product with $\\vec{A}$ is an identity matrix: $\\vec{A}^{-1} \\mm \\vec{A} = I_{N N}$. An $N \\times N$ matrix has an inverse if and only if it has **full rank** $r=N$; this means all of its columns are linerly independent. A matrix which has an inverse is **invertible**. If the inverse exists, the inverse is unique, and it is both a right-inverse and a left-inverse: $\\vec{A} \\mm \\vec{A}^{-1} = \\vec{A}^{-1} \\mm \\vec{A} = I_{N N}$.\n",
    "\n",
    "If $\\vec{A}$ is and $N \\times N$ matrix and $\\vec{b}$ is an $N$-vector, a system of $N$ linear equations in $N$ unknowns can be written in matrix-vector form as $\\vec{A} \\mm \\vec{x} =  \\vec{b}$, where $\\vec{x}$ is an unknown $N$-vector solution to the system of equations. If the matrix $\\vec{A}$ is invertible, its inverse can be used to write down a mathematical formula for the solution of a system of linear equations: $\\vec{x} = \\vec{A}^{-1} \\mm \\vec{b}$.\n",
    "\n",
    "In practice, it is usually not a good idea to solve a system of linear equations using the matrix inverse. Using the matrix inverse can introduce severe numerical error when the matrix is \"almost singular\" (i.e., the columns are \"almost linearly dependendent\" in the sense that one column can be closely approximated by a linear combination of other columns).  It is faster and more accurate to use matrix decompositions, such as the LU decomposition. The numpy function `np.linalg.solve(...)` solves linear equations using a version of LU decomposition. (Matrix decompositions are discussed in the Background Note on ordinary least squares (OLS).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices constructed as rows of sequential integers (interpreted as floating point numbers) may be singular or almost singular.  If a matrix is almost singular, using numpy to calclate its inverse, then multiplying by the inverse to solve a system of linear equations can lead to numerical error.\n",
    "\n",
    "Here is an example illustrating how to solve a system of linear equations $\\vec{A} \\mm \\vec{x} = \\vec{b}$ using `np.linalg.solve(A, B)`.  This example illustrates that solving the same system using `np.linalg.inv(A) @ b` may lead to numerical error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.711855592701269e-16\n",
      "2.2594323164549063e-05\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "noise_constant = 1.0e-10\n",
    "\n",
    "# Create a matrix of normally distributed random noise to be added to the matrix A:\n",
    "noise_matrix = noise_constant * np.random.default_rng(seed=1234).normal(loc=0, scale=1.0, size=(N,N))\n",
    "\n",
    "A = np.array(np.arange(N*N), dtype=np.float64).reshape((N, N)) + noise_matrix \n",
    "b = np.array(np.arange(N), dtype=np.float64)\n",
    "\n",
    "x = np.linalg.solve(A, b)\n",
    "err = A @ x - b\n",
    "print(np.linalg.norm(err))\n",
    "\n",
    "xa = np.linalg.inv(A) @ b\n",
    "erra = A @ xa - b\n",
    "print(np.linalg.norm(erra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Vary the parameters `N` and `noise_constant` in the above example. Is the solution using the matrix inverse `np.linalg.inv(A) @ b` consistently less accurate than the solution using `np.linalg.solve(A, b)`? Does the matrix `A` ever become numerically or mathematically singular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive definite matrix\n",
    "\n",
    "Let $\\vec{A}$ be an $N \\times N$ square matrix and let $\\vec{x}$ be a vector of length $N$. Then the scalar $\\vec{x}\\t @ \\vec{A} @ \\vec{x}$ is called a **quadratic form**. \n",
    "\n",
    "The value of a quadratic form is unchanged if the matrix $\\vec{A}$ is replaced by an average of itself with its transpose: $\\vec{x}\\t \\mm \\vec{A} \\mm \\vec{x} = \\vec{x}\\t \\mm \\frac{1}{2} \\sm (\\vec{A} + \\vec{A}\\t) \\mm \\vec{x}$. Since the average of a matrix with its own transpose is symmetric, matrices which appear in quadratic forms are often assumed to be symmetric (without loss of generality).\n",
    "\n",
    "A matrix $\\vec{A}$ is **positive definite** if $\\vec{x}\\t @ \\vec{A} @ \\vec{x} > 0$ whenever $\\vec{x}$ is not a vector of zeros. A matrix $\\vec{A}$ is **positive semi-definite** if $\\vec{x}\\t @ \\vec{A} @ \\vec{x} \\ge 0$ whenever $\\vec{x}$ is not a vector of zeros. For example, a diagonal matrix is (obviously) positive definite if all of the diagonal elements are strictly positive and is positive semi-definite if all of the diagonal elements are nonnegative. The matrix $\\vec{B} \\t \\mm \\vec{B}$ is positive semi-definite and is positive definite if the rank of $\\vec{B}$ is equal to the number of columns of $\\vec{B}$. \n",
    "\n",
    "It is common to encounter systems of linear equations of the form $\\vec{A} \\mm \\vec{x} = \\vec{b}$ in which the matrix $\\vec{A}$ is positive definite and symmetric.  For example, this happens using ordinary least squares (OLS). In this case, algorithms specialized for positive definite systems of equations provide faster solutions by exploiting the symmetry of the matrix, and these solutions may be more accurate as well. See, for example, `scipy.linalg.solve(A, x, assume_a='pos')`. This is discussed in more detail in the Background Note of ordinary least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row vectors and column vectors in Numpy\n",
    "\n",
    "We can interpret the same one-dimensional array of numbers as a \"column vector\", \"row vector\", or \"plain vector\". A column vector may be represented as an $N \\times 1$ matrix. A row vector may be represented as a $1 \\times N$ matrix. Both row vectors and column vectors have two dimensions, one of which is 1. A plain vector has only one dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a numpy example illustrating the dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=array([100.,  10.,   1.], dtype=float32)\n",
      "xc=array([[100.],\n",
      "       [ 10.],\n",
      "       [  1.]], dtype=float32)\n",
      "xr=array([[100.,  10.,   1.]], dtype=float32)\n",
      "x.shape=(3,), xc.shape=(3, 1), xr.shape=(1, 3)\n",
      "x.ndim=1, xc.ndim=2, xr.ndim=2\n",
      "x.size=3, xc.size=3, xr.size=3\n"
     ]
    }
   ],
   "source": [
    "x = np.array([100, 10, 1], dtype=np.float32)\n",
    "xc = x.reshape(x.shape[0], 1)\n",
    "xr = x.reshape(1, x.shape[0])\n",
    "\n",
    "print(f\"{x=}\\n{xc=}\\n{xr=}\")\n",
    "print(f\"{x.shape=}, {xc.shape=}, {xr.shape=}\")\n",
    "print(f\"{x.ndim=}, {xc.ndim=}, {xr.ndim=}\")\n",
    "print(f\"{x.size=}, {xc.size=}, {xr.size=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing standard matrix operations on a plain one-dimensional vector, numpy guesses what you want, and the guess is usually correct.\n",
    "\n",
    "Consider what happens when multiplying a matrix by a plain vector:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=array([ 10, 100])\n",
      "A=array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5]])\n",
      "res=array([100, 320, 540])\n",
      "\n",
      "x.shape=(2,), A.shape=(3, 2),res.shape=(3,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([10, 100])\n",
    "A = np.array(range(6)).reshape((3, 2))\n",
    "res = A @ x\n",
    "print(f\"{x=}\\n{A=}\\n{res=}\")\n",
    "print(f\"\\n{x.shape=}, {A.shape=},{res.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of multiplying a matrix of shape `(N,M)` by a plain vector of shape `(M,)` is a plain vector of shape `(N,)`. This shape is probably what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "\n",
    "What are the results of the vector-matrix products $\\vec{x} \\mm \\vec{A}$, $\\vec{x} \\mm \\vec{A}\\t$, and $\\vec{x}\\t @ \\vec{A}\\t$. Are these results what you want and expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the results of matrix-vector products using  column vectors (i.e., $N \\times 1$ matrices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=array([[10],\n",
      "       [ 1]])\n",
      "A=array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5]])\n",
      "res=array([[ 1],\n",
      "       [23],\n",
      "       [45]])\n",
      "\n",
      "x.shape=(2, 1), A.shape=(3, 2),res.shape=(3, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([10, 1]).reshape((2,1))\n",
    "A = np.array(range(6)).reshape((3, 2))\n",
    "res = A @ x\n",
    "print(f\"{x=}\\n{A=}\\n{res=}\")\n",
    "print(f\"\\n{x.shape=}, {A.shape=},{res.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a $M \\times 1$ column vector (i.e., a $M \\times 1$ matrix), which is probably what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Illustrate the result of multiplying a row vector by a matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=array([[100,  10,   1]])\n",
      "A=array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5]])\n",
      "res=array([[ 24, 135]])\n",
      "\n",
      "x.shape=(1, 3), A.shape=(3, 2),res.shape=(1, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([100, 10, 1]).reshape((1,3))\n",
    "A = np.array(range(6)).reshape((3, 2))\n",
    "res = x @ A\n",
    "print(f\"{x=}\\n{A=}\\n{res=}\")\n",
    "print(f\"\\n{x.shape=}, {A.shape=},{res.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What is the result of the quadratic form $\\vec{x}\\t \\mm \\vec{A} \\mm \\vec{x}$ when $\\vec{x}$ is a plain vector of shape $(N,)$, column vector of shape $(N,1)$, and row vector of shape $(1,N)$? Is the shape of the result what you want? Do you get an error when you want an error? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal functions in Numpy\n",
    "\n",
    "When using vectors and matrices, one frequently wants to apply functions \"element-by-element\" to the vectors and matrices.\n",
    "\n",
    "Numpy implements this with the concept of a **U-funnction**. Many functions are automatically implemented element by element, including addition, subtraction, multiplication, division, exponentiation, and logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1=array([  1.5,  12.5, 112.5]), res2=array([  1.55144471,  10.00181435, 100.        ])\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 10, 100], dtype=np.float64)\n",
    "y = np.array([2, 4, 8], dtype=np.float64)\n",
    "\n",
    "res1 = x / y + np.abs(x) \n",
    "res2 = np.log(np.exp(x) + x * y)\n",
    "\n",
    "print(f\"{res1=}, {res2=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Numpy has rules according to which element-by-element operations can be broadcast across arrays of compatible shapes, even when the shapes are not exactly the same.\n",
    "\n",
    "When performing operations involving scalars and arrays, numpy will broadcast the scalar to every element of the array. An example is scalar multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10. 15.]\n",
      " [20. 25.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array(np.arange(4)).reshape((2,2))\n",
    "print(5.00 * A + 10.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When arrays are the same shape, numpy performs operations element by element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0. 101. 202.]\n",
      " [303. 404. 505.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array(np.arange(6)).reshape((2,3))\n",
    "B = np.array(np.arange(6)).reshape((2,3)) * 100.0\n",
    "print(A + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When asked to perform element-by-element operations on arrays of different shapes, numpy will attempt to increase the size of individual dimensions from 1 to a larger number so that a result of consistent shape can be created.\n",
    "\n",
    "For example, when a row vector is added to a matrix, the row vector is added to each row of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=array([[0, 1, 2],\n",
      "       [3, 4, 5]])\n",
      "x=array([[  10,  100, 1000]])\n",
      "res=array([[  10,  101, 1002],\n",
      "       [  13,  104, 1005]])\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(6).reshape(2,3)\n",
    "x = np.array([10, 100, 1000]).reshape((1,3))\n",
    "res = A + x\n",
    "print(f\"{A=}\\n{x=}\\n{res=}\")\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "Give an example of adding a column vector to a matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When broadcasting over arrays whose shapes have a different number of dimensions (e.g., adding a one-dimensional column vector to a two-dimensional matrix) numpy will implicitly increase the number of dimensions by adding dimensions of size 1 on the left. When a plain vector of shape `(N,)` is added to a matrix of shape `(N, N)`, the vector is implicitly converted to a row vector of shape `(1, N)`. \n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=array([[0, 1],\n",
      "       [2, 3]])\n",
      "x2=array([ 10, 100])\n",
      "\n",
      "x.shape=(2,)\n",
      "A + x=array([[ 10, 101],\n",
      "       [ 12, 103]])\n",
      "\n",
      "x.shape=(1, 2)\n",
      "A + x=array([[ 10, 101],\n",
      "       [ 12, 103]])\n",
      "\n",
      "x.shape=(2, 1)\n",
      "A + x=array([[ 10,  11],\n",
      "       [102, 103]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(4).reshape(2,2)\n",
    "x2 = np.array([10, 100])\n",
    "x12 = x2.reshape((1,2))\n",
    "x21 = x2.reshape((2,1))\n",
    "print(f\"{A=}\\n{x2=}\\n\")\n",
    "\n",
    "for x in [x2, x12, x21]:\n",
    "    res = print(f\"{x.shape=}\\n{A + x=}\\n\")\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, adding the plain vector of shape `(2,)` to a matrix of shape `(2, 2)` is error-prone because you get the effect of adding a row vector when you may have intended to add a  columns vector! Python typically generates an error when code might otherwise be error-prone; this case is an exception. One advantage of specifying whether a vector is a row vector of shape `(1, N)` or column vector of shape `(N, 1)` is that can make clear whether you want element-by-element operations to propagate across rows or columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-dimensional arraya\n",
    "\n",
    "Numpy also allows arrays with zero dimensions containing one scalar. When broadcasting, these are converted to shapes `(1,)`, `(1, 1)`, etc. as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=array(100), x[()]=100, x.shape=()\n",
      "A + x = array([[100, 101],\n",
      "       [102, 103]])\n"
     ]
    }
   ],
   "source": [
    "A = np.array(np.arange(4)).reshape((2,2))\n",
    "x = np.array(100)\n",
    "print(f\"{x=}, {x[()]=}, {x.shape=}\\n{A + x = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A numpy array with zero dimensions, created from a Python `float`, is an objec of type `np.ndarray` containing one element of type `np.float64`, which can be converted back to the original Python float with the `np.ndarray.item()` function.\n",
    "\n",
    "Consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0=99.99, type(x0)=<class 'float'>\n",
      "x=array(99.99), type(x)=<class 'numpy.ndarray'>, x.shape=(), x.size=1\n",
      "x[()]=99.99,type(x[()])=<class 'numpy.float64'>\n",
      "x.item()=99.99, type(x.item())=<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "x0 = 99.99 # Python float\n",
    "x = np.array(x0) #zero-dimensional numpy array\n",
    "print(f\"{x0=}, {type(x0)=}\\n{x=}, {type(x)=}, {x.shape=}, {x.size=}\\n{x[()]=},{type(x[()])=}\\n{x.item()=}, {type(x.item())=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Verify that the function `item()` can be applied to numpy arrays with dimension 1 and 2 as long as the `size` is one, (i.e., the `item()` function works with arrays of size `(1,)` and `(1,1)`.\n",
    "                                                                                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subarrays, which may share data\n",
    "\n",
    "We can access the rows, columns and arbitrary submatrices of a matrix using indexing functions. The $n$th row of a matrix $A$ is denoted $A[n, :]$. This is an example of creating a **slice**.\n",
    "\n",
    "Important: The subarrays share the same data with the array itself. If you do not want the arrays to share the same data, use the `copy()` function.\n",
    "\n",
    "There are slightly different ways of referring to the $n$th row of a matrix, depending upon whether you want a plain vector or a row vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = array([[    0,     1,     2,     3],\n",
      "       [    4,     5,     6, 77777],\n",
      "       [    8,     9,    10,    11]])\n",
      "xa = array([    4,     5,     6, 77777]) = plain vector, shares data, xa.shape=(4,)\n",
      "\n",
      "A = array([[    0,     1,     2,     3],\n",
      "       [    4,     5,     6, 77777],\n",
      "       [    8,     9,    10,    11]])\n",
      "xac = array([4, 5, 6, 7]) = plain vector, does not share data, xac.shape=(4,)\n",
      "\n",
      "A = array([[    0,     1,     2,     3],\n",
      "       [    4,     5,     6, 77777],\n",
      "       [    8,     9,    10,    11]])\n",
      "xb= array([[    4,     5,     6, 77777]]) = row vector, shares data, xb.shape=(1, 4)\n",
      "\n",
      "A = array([[    0,     1,     2,     3],\n",
      "       [    4,     5,     6, 77777],\n",
      "       [    8,     9,    10,    11]])\n",
      "xbc= array([[4, 5, 6, 7]]) = row vector, does not share data, xbc.shape=(1, 4)\n"
     ]
    }
   ],
   "source": [
    "A = np.array(np.arange(12)).reshape(3,4)\n",
    "xa = A[1, :]\n",
    "xac = A[1, :].copy()\n",
    "xb = A[1:2, :]\n",
    "xbc = xb.copy()\n",
    "A[1,3] = 77777\n",
    "print(f\"{A = }\\n{xa = } = plain vector, shares data, {xa.shape=}\")\n",
    "print(f\"\\n{A = }\\n{xac = } = plain vector, does not share data, {xac.shape=}\")\n",
    "print(f\"\\n{A = }\\n{xb= } = row vector, shares data, {xb.shape=}\")\n",
    "print(f\"\\n{A = }\\n{xbc= } = row vector, does not share data, {xbc.shape=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Show how to obtain the second colum of matrix $A$ a a column vector which does not share data with $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing submatrices of an array\n",
    "\n",
    "Submatrices of an array may be changed by slicing. Consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = array([[ 0,  1,  2,  3],\n",
      "       [ 4,  5,  6,  7],\n",
      "       [ 8,  9, 10, 11]])\n",
      "A = array([[  0, 100, 200, 300],\n",
      "       [  4, 400, 500, 600],\n",
      "       [  8,   9,  10,  11]])\n"
     ]
    }
   ],
   "source": [
    "A = np.array(np.arange(12)).reshape((3, 4))\n",
    "print(f\"{A = }\")\n",
    "A[0:2, 1:] = np.array(100.0 * np.arange(1, 7)).reshape((2, 3))\n",
    "print(f\"{A = }\")\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprises with Immutability\n",
    "\n",
    "Suppose you have a Python tuple with two elements of type `float`. Then it is not easy to change the value of the two floats in the tuple.\n",
    "\n",
    "If you would like to change one of the elements of the tuple, you can let this element be a numpy array containing only one scalar. Then change the numpy array by using indexing, such as `x[()] = 123.456`. If you use, `x = np.array(123.456)`, a new object is created, and the tuple continues to refer to the original object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, array(2.), array(3.), array([4.]))\n",
      "(1.0, array(22.22), array(3.), array([44.44]))\n"
     ]
    }
   ],
   "source": [
    "x = 1.00\n",
    "y = np.array(2.00)\n",
    "z = np.array(3.00)\n",
    "w = np.array([4.00])\n",
    "t = (x, y, z, w)\n",
    "print(t)\n",
    "x = 11.11\n",
    "y[()] = 22.22\n",
    "z = np.array(33.33)\n",
    "w[0] = 44.44\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Suppose a tuple contains numpy arrays of size 1, but you do not want the data in the tuple to change if the data in the numpy array changes. Show that this can be accomplished by using the `item()` function when the tuple is created.  If an array `a` is a plain vector (i.e., has one dimension) containing more than one element, show that this can be accomplished using the `tuple(a)` constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays with more than 2  dimensions\n",
    "\n",
    "Numpy used to have a separate matrix class, which was distinct from the two dimensional `np.ndarray`.  This has been deprecated in favor of using 2-dimensional arrays as matrices.\n",
    "\n",
    "Numpy also allows arrays with more than 2 dimensions. Here is an example of a 3-dimensional array. Note the three levels of square brackets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array(range(30)).reshape((2,3,5))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy's Additional Features\n",
    "\n",
    "Numpy has many features which are not exactly linear algebra.  These features are not covered in this note.  Some of them include:\n",
    "\n",
    "* **Reduction operations** (other than inner products, matrix-vector products, and matrix-matrix products) such as summing across rows  or columns of arrays. Reduction operations reduce the number of dimensions of an array.\n",
    "\n",
    "* Functions to replace algorithms which would otherwise require slow Python loops.\n",
    "\n",
    "* Boolean arrays and operations with boolean variables, including indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!!\n"
     ]
    }
   ],
   "source": [
    "print(\"finished!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
